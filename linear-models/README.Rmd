---
title: "Linear models Notes"
output: github_document
---

**Explanatory Variable**  
Also known as the `independent` or `predictor variable`, it explains
variations in the response variable; in an experimental study, it is
manipulated by the researcher

**Response Variable**  
Also known as the `dependent` or `outcome variable`, its value is
predicted or its variation is explained by the explanatory variable; in
an experimental study, this is the outcome that is measured following
manipulation of the explanatory variable

![Response and Explanatory variable](https://images.deepai.org/django-summernote/2019-06-18/fe2a668a-625f-431f-9472-e177d594ba2c.png)

**Example 1**

A team of veterinarians wants to compare the effectiveness of two
fertility treatments for pandas in captivity. The two treatments are
in-vitro fertilization and male fertility medications. This experiment
has one explanatory variable: type of fertility treatment. The response
variable is a measure of fertility rate.

`Factor variables` are categorical variables that can be either numeric
or string variables. There are a number of advantages to converting
categorical variables to factor variables.

## Model Selection

It is a process of selecting a model from a set of candidate models.

It can either be implicit or explicit in the following ways:
1.Hypothesis tests require selecting between a null hypothesis and
alternative hypothesis model.  
2.An auto-regressive model requires selecting the order p.  
3.Selecting specific predictors.

A good model selection technique will balance
`goodness of fit or simplicity`

## Extentions of the linear models

Linear model have highly restrictive assumptions:

-   There is a linear and additive relationship between the response and
    the predictor.  
-   additive assumptions means that the effect of changes in a predictor
    $X_j$ on the response $Y$ is independent of the values
    of the other predictors.

### Removing the additive assumption

Consider
$$ Y = \beta_0 +\beta_1 X_1 +\beta_2 X_2 + \epsilon $$

The model can be extended by adding `an interaction term` which is
constructed by computing the pr product of *X*<sub>1</sub> and
*X*<sub>2</sub>. This result in the model
$$ Y = \beta_0 +\beta_1 X_1 +\beta_2 X_2 + \epsilon $$

